---
layout: post
title: 聚类结果评价指标
date: 2017-12-30
categories: [机器学习, ML]
---

多种常见聚类模型以及分群质量评估（聚类注意事项、使用技巧）参见[悟乙己的博文](http://blog.csdn.net/sinat_26917383/article/details/51611519)

一、样本给定标记时的评价指标

1. 准确性（Cluster Accuracy，CA）

计算
$$ CA=\sum_{i=1}^K\frac{max(C_i|L_i)}{|\Omega |} $$
聚类正确的百分比，值越大证明聚类效果越好。

2. 兰德指数

兰德指数（Rand index）需要给定实际类别信息C，
假设K是聚类结果，a表示在C与K中都是同类别的元素对数，b表示在C与K中都是不同类别的元素对数，则兰德指数为：
$$RI=\frac{a+b}{C^{n_{samples}}_2}$$
其中$C^{n_{samples}}_2$
数据集中可以组成的总元素对数，$RI$取值范围为[0,1]，值越大意味着聚类结果与真实情况越吻合。

对于随机结果，RI并不能保证分数接近零。为了实现“在聚类结果随机产生的情况下，指标应该接近零”，
调整兰德系数（Adjusted rand index）被提出，它具有更高的区分度：
\[ARI=\frac{RI−E[RI]}{max(RI)−E[RI]}\]
具体计算方式参见[Adjusted Rand index](https://en.wikipedia.org/wiki/Rand_index#Adjusted_Rand_index)。

$ARI$取值范围为[−1,1]，值越大意味着聚类结果与真实情况越吻合。从广义的角度来讲，ARI衡量的是两个数据分布的吻合程度。

3. 互信息

互信息（Mutual Information）也是用来衡量两个数据分布的吻合程度。
假设U与V是对N个样本标签的分配情况，则两种分布的熵（熵表示的是不确定程度）分别为：
\[H(U)=\sum^{|U|}_{i=1}P(i)log(P(i)),
H(V)=\sum_{j=1}^{|V|}P′(j)log(P′(j))\]
其中，$P(i)=\frac{|U_i|}{N},P′(j)=\frac{|V_j|}{N}$。U与V之间的互信息（MI）定义为：
\[MI(U,V)=\sum_{i=1}^{|U|}\sum_{j=1}^{|V|}P(i,j)log\frac{P(i,j)}{P(i)P′(j)}\]
其中，$P(i,j)=\frac{|U_i⋂V_j|}{N}$。标准化后的互信息（Normalized mutual information）为：
\[NMI(U,V)=\frac{MI(U,V)}{\sqrt{H(U)H(V)}}\]
与ARI类似，调整互信息（Adjusted mutual information）定义为：
\[AMI=\frac{MI−E[MI]}{max(H(U),H(V))−E[MI]}\]
利用基于互信息的方法来衡量聚类效果需要实际类别信息，MI与NMI取值范围为[0,1]，
AMI取值范围为[−1,1]，它们都是值越大意味着聚类结果与真实情况越吻合。

4. 同质性和完整性
同质性（Homogeneity）：每个群集中只包含单个类的成员。
完整性（Completeness）：给定类的所有成员都分配给同一个群集。
V-measure：同质性和完整性的调和平均。

5. Fowlkes-Mallows Scores（FMI）
FMI是成对的precision（精度）和recall（召回）的几何平均数。定义为：
\[ FMI=\frac{TP}{\sqrt{(TP+FP)(TP+FN)}} \]

二、样本不给定标记时的评价指标

6. 紧密性（Compactness，CP）

计算
$$ \overline{CP_i}=
\frac{1}{|\Omega_i|}\sum_{x_i\in \Omega_i}\lVert x_i-w_i\rVert \ , \
\overline{CP}=\frac{1}{K}\sum_{k=1}^K\overline{ {CP}_k}
$$
每一个类各点到聚类中心的平均距离CP，值越低意味着类内聚类距离越近。缺点是没有考虑类间效果。

7. 间隔性（Separation，SP）

计算
\[ \overline{SP}=\frac{2}{k^2-k}\sum_{i=1}^k\sum_{j=i+1}^k\lVert w_i-w_j\rVert \]
各聚类中心两两之间平均距离，SP越高意味类间聚类距离越远。缺点是没有考虑类内效果。

8. 戴维森堡丁指数（Davies-Bouldin Index，DB/DBI）分类适确性指标

计算
\[ DB=\frac{1}{k}\sum_{i=1}^k{\underset{j\neq i}{max}}
\left(\frac{\overline{C_i}+\overline{C_j}}
{\lVert w_i - w_j \rVert}_2
\right)
\]
任意两类别的类内距离平均距离(CP)之和除以两聚类中心距离的最大值。值越小意味着类内距离越小，同时类间距离越大。缺点是因使用欧式距离，所以对于环状分布聚类评测很差。

9. 轮廓系数(Sihouette Coefficient)

轮廓系数（Silhouette coefficient）适用于实际类别信息未知的情况。
对于单个样本，设a是与它同类别中其他样本的平均距离，b是与它距离最近不同类别中样本的平均距离，轮廓系数为：
\[s=\frac{b−a}{max(a,b)}\]
对于一个样本集合，它的轮廓系数是所有样本轮廓系数的平均值。轮廓系数取值范围是[−1,1]，同类别样本越距离相近且不同类别样本距离越远，分数越高。

10. Calinski-Harabaz Index

这个计算简单直接，使用簇内的稠密程度和簇间的离散程度来评估聚类的效果。得到的Calinski-Harabasz分数值s越大则聚类效果越好。Calinski-Harabasz分数值s的数学计算公式是:
\[ s(k)=\frac{tr(B_k)}{tr(W_k)}\frac{m-k}{k-1}\]
其中，m为训练集样本数，k为类别数。$B_k$为类别之间的协方差矩阵，$W_k$类别内部数据的协方差矩阵。tr为矩阵的迹。

也就是说，类别内部数据的协方差越小越好，类别之间的协方差越大越好，这样的Calinski-Harabasz分数会高。在真实的分群label不知道的情况下，可以作为评估模型的一个指标。同时，数值越小可以理解为：组间协方差很小，组与组之间界限不明显。与轮廓系数的对比，最大的优势就是快！相差几百倍！毫秒级。

11. 邓恩指数（Dunn Validity Index， DVI）

计算
\[ DVI=\frac{
  \underset{0<m\neq n<K}{min}
  \left\{
    \underset{\underset{\forall x_j\in\Omega_n}{\forall x_j\in\Omega_m}}{min}
    \left\{\lVert x_i-x_j \rVert \right\}
  \right\}
}
{
  \underset{0<m\leq K}{max}\ \underset{\forall x_i,x_j\in\Omega_m}{max}
  \lVert x_j - x_j \rVert
}
\]
任意两个簇元素的最短距离(类间)除以任意簇中的最大距离(类内)。DVI越大意味着类间距离越大，同时类内距离越小。缺点是对离散点的聚类测评很高、对环状分布测评效果差。

参考文献

[机器学习评价指标大汇总](https://www.cnblogs.com/zhaokui/p/ml-metric.html)

[sklearn聚类算法评估方法之各种系数](http://blog.csdn.net/u010159842/article/details/78624135)

[用scikit-learn学习K-Means聚类](http://www.cnblogs.com/pinard/p/6169370.html)

[聚类算法评价指标](http://blog.csdn.net/sinat_33363493/article/details/52496011)
